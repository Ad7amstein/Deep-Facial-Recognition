# Deep Facial Recognition ğŸ§ ğŸ‘ï¸

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?&logo=pytorch&logoColor=white)](https://pytorch.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenCV](https://img.shields.io/badge/OpenCV-%23white.svg?&logo=opencv&logoColor=white)](https://opencv.org)
[![Kivy](https://img.shields.io/badge/Kivy-2.0.0%2B-green.svg)](https://kivy.org)

A facial verification system using a Siamese Neural Network architecture built with PyTorch. This project enables real-time facial recognition with a webcam to verify if a person matches registered faces in the verification database.

## Application Demo

| Verified (Hi 3llam ğŸ«¡) âœ… | Unverified (Not Recognized âŒ) |
|:-------------------------:|:-------------------------:|
|![Verified Face](assets/verified_img.png) | ![Unverified Face](assets/unverified_img.png)|
|*System recognizes the registered face* | *System doesn't recognize the face* |

## Overview ğŸ”

This system uses one-shot learning via a Siamese network to perform facial verification without requiring large datasets of the target individual. The model compares an input face against a database of verification images and determines if it's a match based on configurable thresholds.

## Features âœ¨

- **Siamese Neural Network** ğŸ”„: Utilizes twin networks with shared weights for facial comparison
- **One-Shot Learning** ğŸ“¸: Requires only a small set of reference images
- **Real-time Verification** âš¡: Process webcam feed for instant facial verification
- **Customizable Thresholds** ğŸ›ï¸: Adjustable detection and verification thresholds
- **Desktop Application** ğŸ–¥ï¸: Built with Kivy for cross-platform GUI interface

## Project Structure ğŸ“

```
Deep-Facial-Recognition/
â”œâ”€â”€ app/                        # Main application folder
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ faceid.py               # Kivy application for real-time verification
â”‚   â”œâ”€â”€ model.py                # Neural network model architecture
â”‚   â”œâ”€â”€ siamese_network_v2.pth  # Trained model weights
â”‚   â””â”€â”€ application_data/       # Application data directory
â”‚       â”œâ”€â”€ input_image/        # Stores input image from webcam
â”‚       â””â”€â”€ verification_images/ # Reference images to compare against
â”œâ”€â”€ application_data/           # Root application data (mirror of app/application_data)
â”œâ”€â”€ data/                       # Training data directory
â”‚   â”œâ”€â”€ anchor/                 # Anchor images (training)
â”‚   â”œâ”€â”€ positive/               # Positive images (training)
â”‚   â””â”€â”€ negative/               # Negative images (training)
â”œâ”€â”€ models/                     # Stored model weights
â”œâ”€â”€ training_checkpoints/       # Training checkpoint files
â””â”€â”€ Facial Verification with a Siamese Network.ipynb  # Training notebook
```

## Technical Details ğŸ”¬

### Model Architecture ğŸ—ï¸

The system implements a Siamese Neural Network with:

- `Embedding network` with CNN layers for feature extraction ğŸ§©
- `L1 Distance layer` to compute similarity between embeddings ğŸ“
- `Classification layer` to determine verification probability ğŸ“Š

### Training Process ğŸ‹ï¸â€â™‚ï¸

The model was trained in two distinct phases:

**Phase 1** ğŸ“Š:

- Training on 300 image samples with no augmentation
- Resulted in initial model (siamese_network.pth)
- Established baseline performance

**Phase 2** ğŸ“ˆ:

- Training on 3000 image samples with data augmentation
- Applied transformations including random flips, brightness/contrast adjustments
- Produced the final optimized model (siamese_network_v2.pth)
- Significant improvement in accuracy and generalization

The model was trained using triplets of:

- Anchor images (reference face) âš“
- Positive images (same person as anchor) âœ…
- Negative images (different person) âŒ

The model learns to minimize the distance between anchor-positive pairs while maximizing the distance between anchor-negative pairs.

## Installation and Usage ğŸš€

### Prerequisites ğŸ“‹

- Python 3.8+ ğŸ
- PyTorch ğŸ”¥
- OpenCV ğŸ‘ï¸
- Kivy (for the desktop GUI application) ğŸ–¼ï¸
- PIL (Pillow) ğŸ–¼ï¸

### Setup âš™ï¸

1. Clone the repository:

```bash
git clone https://github.com/yourusername/Deep-Facial-Recognition.git
cd Deep-Facial-Recognition
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Running the application:

```bash
cd app
python faceid.py
```

### Using the Application ğŸ“±

1. Launch the desktop application ğŸ–¥ï¸
2. Position your face in the camera frame ğŸ˜Š
3. Click "Verify" button to check if your face matches the verification database ğŸ”
4. Result will be displayed on screen âœ“

## Training Your Own Model ğŸ§ 

The complete training process is documented in the Jupyter notebook. To train with your own data:

1. Collect images for the anchor, positive, and negative directories ğŸ“¸
2. Run the notebook cells to:
   - Preprocess images ğŸ”„
   - Create the dataset ğŸ“¦
   - Train the Siamese network ğŸ‹ï¸â€â™‚ï¸
   - Evaluate and save the model ğŸ’¾

## License ğŸ“œ

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments ğŸ™

- The Labeled Faces in the Wild dataset was used for negative samples during training
- This project implements concepts from the paper [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) by Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov (2015)
